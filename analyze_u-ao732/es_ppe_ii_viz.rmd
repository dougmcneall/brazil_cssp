---
title: Visualising a large perturbed parameter ensemble of the land surface model
  JULES
output:
  html_document:
    df_print: paged
---

```{r, message = FALSE}
source('es_ppe_ii_viz.fun.R')
source('../per_pft.R')

```

```{r}
# -----------------------------------------------------------------------------------
# Load data
# -----------------------------------------------------------------------------------

years = 1861:2014
ysec = 60*60*24*365
norm.vec = c(1e12, 1e12, 1e12/ysec , 1e12, 1e12, 1e9)

# Load up the data
lhs_i = read.table('data/ES_PPE_i/lhs_u-ao732.txt', header = TRUE)
lhs_ii = read.table('data/ES_PPE_ii/lhs_u-ao732a.txt', header = TRUE)

toplevel.ix = 1:499

lhs = rbind(lhs_i, lhs_ii)[toplevel.ix, ]

X = normalize(lhs)
colnames(X) = colnames(lhs)
d = ncol(X)
# lower and higher bound on the normalised matrix for visualisation
rx = rbind(rep(0,32), rep(1,32))

fnallvec = dir('data/ES_PPE_ii_test/', pattern = 'Annual')
# WARNING - hard coded hack to sort
fidx = grep("Annual.(?!Amazon).*", fnallvec, perl=TRUE)
fnvec_interim = fnallvec[fidx]
fidx2 = grep("sum.(?!standard).*", fnvec_interim, perl=TRUE)
fnvec = fnvec_interim[fidx2]
fnlocvec = paste0('data/ES_PPE_ii_test/', fnvec)

# Extract the bit of the filename that describes the data
fs = lapply(fnvec,regexpr, pattern = 'Annual')
fe = lapply(fnvec,regexpr, pattern = 'global_sum.txt')

fnams = rep(NA, length(fnvec))
for(i in 1:length(fnvec)){
  fnams[i] = substr(fnvec[i], attr(fs[[1]], 'match.length')+2, fe[[i]][1]-2)
}

# Constrain on runoff first
datmat.raw = matrix(nrow = nrow(X), ncol = length(fnlocvec))
for(i in 1:length(fnlocvec)){
  dat = load_ts_ensemble(fnlocvec[i])[toplevel.ix, ]
  dat.modern = dat[ ,135:154]
  mean.modern = apply(dat.modern, 1, mean)
  datmat.raw[ , i] = mean.modern
}
colnames(datmat.raw) = fnams

# Here 'normalised' means to a convenient unit (such as Sv for runoff)
dat.norm = sweep(datmat.raw, 2, norm.vec, FUN = '/')
p = ncol(dat.norm)
head(dat.norm)

```

## A "level 0" constraint  
A quick look at the histograms of the ensemble output show that there are a number of ensemble members with very low (close to zero) runoff. Inspecting these shows that they are highly unrealistic in lots of other ways as well (e.g. very low gpp/npp). This offers an opportunity to remove runs early on that might reduce the accuracy of an emulator - a "level 0" constraint.    

```{r}
par(mfrow = c(3,2))
for(i in 1:6){
  hist(dat.norm[,i], main = fnams[i])
}

```

Here is the runoff plotted against each parameter - there are plenty of unrealistically low ensemble members.

```{r}
par(mfrow = c(4, 8), mar = c(1,1,2,1))
for(i in 1:d){
  plot(lhs[ ,i],dat.norm[ ,6], axes = FALSE, xlab = '', ylab = '',
       main = colnames(lhs)[i], cex.main = 0.8)
}
```
We remove any ensemble member with runoff less than or equal to 0.5 Sv, and NBP less that -10
```{r}
allix = 1:(nrow(dat.norm))

# Constrain with global runoff and nbp, so that the emulator
# is not negatively affected by really bad points
level0.ix = which(dat.norm[,'runoff'] >0.5 & dat.norm[,'nbp'] > -10)
dat.level0  = dat.norm[level0.ix, ]
X.level0 = X[level0.ix, ]
lhs.level0 = lhs[level0.ix, ]

nlevel0.ix = setdiff(allix, level0.ix)
X.nlevel0 = X[nlevel0.ix, ]
lhs.nlevel0 = lhs[nlevel0.ix, ]

# These are the ensemble members which do not run (produce NA)
na.ix = which(is.na(dat.norm[,'runoff']))
X.na = X[na.ix, ]
lhs.na = lhs[na.ix, ]

lhs.rx = round(apply(lhs,2,range),1)

```

Plotting the remaining members shows that many of the members with low GPP and NPP have been removed as well.

```{r}
# Visualise the constrained space ...
mins  = apply(X.level0, 2, min)
maxes = apply(X.level0, 2, max)

par(mfrow = c(3,2))
for(i in 1:6){
  hist(dat.norm[level0.ix,i], main = fnams[i])
}
```

## Parallel coordinates plots of input space with a level 0 constraint

```{r, fig.width=10, fig.height=6}
# Parallel Coordinates plot of NROY and ruled out members, level 0
#dev.new(width = 20, height = 9)
#pdf(file = 'graphics/pcp_level0.pdf', width = 20, height = 9)
par(mfrow = c(2,1), las = 2, mar = c(7,4,4,1), cex.axis = 0.8)

# This function doesn't recale the maximum and minimum of each parameter, so you can easier see where there are gaps.
parcoord.notsilly(X.level0, rx, col = makeTransparent('black', 100), ylim = c(0,1),
         main = 'level 0 NROY ensemble members', var.label = TRUE)
                  
parcoord.notsilly(X.nlevel0, rx, col = makeTransparent('black', 100), ylim = c(0,1),
         main = 'level 0 ruled out ensemble members', var.label = TRUE)
                  
parcoord.notsilly(X.na,rx, col = makeTransparent('red', 255), add = TRUE)

reset()
legend('left',
       legend = 'Did Not Run',
       inset = 0.1,
       col = 'red',
       cex = 1.2,
       lwd = 2,
       horiz = TRUE)
```

The parallel coordinates plot on the top show those ensemble members that are NOT Ruled Out Yet (NROY) by the "level 0" constraints. The bottom shows those that are ruled out by the constraints (black) and those ensemble members that did not run at all (red). On the bottom diagram, you can see how many ensemble members fail to run when b_wl is low, suggesting that the lower limit of that parameter is set too low. Similarly, you can see that the initial constraints rule out many members when F0_io is high and b_wl is low, suggesting that this particular combination of parameters causes problems with the modelling.


## Pairs plot of ruled-out ensemble member input settings  

```{r, fig.width = 10, fig.height = 10}
# Pairs plot of level 0 constraint

# Pairs plot of level 0 constraint excluded members is much easier to interpret
#dev.new(width = 10, height = 10)
#pdf(file = 'graphics/pairs_nlevel0.pdf', width = 10, height = 10)
pairs(rbind(X.nlevel0, X.na), gap = 0, lower.panel = NULL,
      labels = 1:d,
      cex.lab = 0.8,
      xlim = c(0,1), ylim = c(0,1),
      col = c(rep(makeTransparent('black', 50), nrow(X.nlevel0)), rep(makeTransparent('red', 100), nrow(X.na))),
      pch = 20,
      xaxt = 'n', yaxt = 'n'
      )
par(xpd = NA)
#text(0.2, 0.6, labels = paste0(colnames(lhs)[1:5],'\n'))

legend('left', legend = paste(1:d, colnames(lhs)), cex = 0.9, bty = 'n')
mtext(side = 1, text = 'Level 0 ruled out ensemble members', cex = 2)
reset()
legend('bottom',
       legend = c('Ruled out', 'Did Not Run'),
       inset = 0.15,
       col = c(makeTransparent('black', 50),makeTransparent('red', 100)),
       cex = 1.1,
       pch = 20,
       horiz = TRUE)
#dev.off()

```
A pairs plot of the ensemble members that did not run (red) or were ruled out by the level 0 constraints (black).


## Level 1 constraints
```{r, fig.width = 7, fig.height = 7}

# Histogram of level 1 constraints
hcol = 'darkgrey'
lcol = 'black'
par(mfrow = c(3,2), fg = 'darkgrey', las = 1)

hist(dat.norm[,'runoff'], col = hcol, main = 'Runoff', xlab = 'Sv')
polygon(x = c(0.5, 100, 100, 0.5), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
        border = makeTransparent('tomato2'))
hist(dat.norm[,'nbp'], col = hcol, main = 'NBP', xlab = 'GtC/year')
polygon(x = c(-10, 100, 100, -10), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
        border = makeTransparent('tomato2'))
hist(dat.norm[,'cs_gb'], col = hcol, main = 'Soil Carbon', xlab = 'GtC')
polygon(x = c(750, 3000, 3000, 750), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
        border = makeTransparent('tomato2'))

hist(dat.norm[,'cv'], col = hcol, main = 'Vegetation Carbon', xlab = 'GtC')
polygon(x = c(300, 800, 800, 300), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
       border =  makeTransparent('tomato2'))
hist(dat.norm[,'npp_n_gb'], col = hcol , main = 'NPP', xlab = 'GtC/year')
polygon(x = c(35, 80, 80, 35), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
        border = makeTransparent('tomato2')
)

```
The histograms show the location of some initial "level 1" constraints. These are the limits that the modeller (Andy Wiltshire) is willing to tolerate in a number of carbon cycle outputs before rejecting the ensemble member as useless.








